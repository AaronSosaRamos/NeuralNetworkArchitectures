{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Siamese Networks:\n",
        "Siamese networks are designed to learn similarity between two inputs. They consist of two identical subnetworks (or branches) with shared weights. These networks are used for tasks like face verification, signature verification, and similarity-based recommendation systems."
      ],
      "metadata": {
        "id": "HNL_bjKsGrOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOeSZIAtEL3e",
        "outputId": "c92d21d7-2fcc-41a2-a674-60342aff07f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "938/938 [==============================] - 10s 9ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 8s 9ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 7.6246 - accuracy: 0.5000 - val_loss: 7.6246 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x781b51f91bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define the Siamese network architecture\n",
        "def create_siamese_network(input_shape):\n",
        "    # Define the base network (shared subnetwork)\n",
        "    input = layers.Input(shape=input_shape)\n",
        "    x = layers.Flatten()(input)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    base_network = models.Model(input, x)\n",
        "\n",
        "    # Define the two input branches of the Siamese network\n",
        "    input_a = layers.Input(shape=input_shape)\n",
        "    input_b = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Connect each input to the base network\n",
        "    processed_a = base_network(input_a)\n",
        "    processed_b = base_network(input_b)\n",
        "\n",
        "    # Calculate L1 distance between the processed inputs\n",
        "    distance = tf.reduce_sum(tf.abs(processed_a - processed_b), axis=1, keepdims=True)\n",
        "\n",
        "    # Create the Siamese model\n",
        "    siamese_model = models.Model([input_a, input_b], distance)\n",
        "\n",
        "    return siamese_model\n",
        "\n",
        "# Instantiate the Siamese network\n",
        "input_shape = x_train.shape[1:]\n",
        "siamese_model = create_siamese_network(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "def create_pairs(x, y, num_classes):\n",
        "    pairs, labels = [], []\n",
        "    class_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
        "\n",
        "    for class_idx in range(num_classes):\n",
        "        for i in range(len(class_indices[class_idx])):\n",
        "            x1 = x[class_indices[class_idx][i]]\n",
        "            label1 = class_idx\n",
        "\n",
        "            # Create a positive pair (same class)\n",
        "            idx2 = i + 1 if i + 1 < len(class_indices[class_idx]) else 0\n",
        "            x2 = x[class_indices[class_idx][idx2]]\n",
        "            pairs.append([x1, x2])\n",
        "            labels.append(1)\n",
        "\n",
        "            # Create a negative pair (different class)\n",
        "            other_class_idx = (class_idx + 1) % num_classes\n",
        "            other_class_indices = class_indices[other_class_idx]\n",
        "            random_idx = np.random.choice(len(other_class_indices))\n",
        "            x2 = x[other_class_indices[random_idx]]\n",
        "            pairs.append([x1, x2])\n",
        "            labels.append(0)\n",
        "\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "# Create pairs for training and validation\n",
        "num_classes = len(np.unique(y_train))\n",
        "train_pairs, train_labels = create_pairs(x_train, y_train, num_classes)\n",
        "test_pairs, test_labels = create_pairs(x_test, y_test, num_classes)\n",
        "\n",
        "# Train the Siamese network\n",
        "siamese_model.fit([train_pairs[:, 0], train_pairs[:, 1]], train_labels,\n",
        "                  validation_data=([test_pairs[:, 0], test_pairs[:, 1]], test_labels),\n",
        "                  batch_size=128,\n",
        "                  epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define the Siamese network architecture\n",
        "def create_siamese_network(input_shape):\n",
        "    # Define the base network (shared subnetwork)\n",
        "    input = layers.Input(shape=input_shape)\n",
        "    x = layers.Flatten()(input)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    base_network = models.Model(input, x)\n",
        "\n",
        "    # Define the two input branches of the Siamese network\n",
        "    input_a = layers.Input(shape=input_shape)\n",
        "    input_b = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Connect each input to the base network\n",
        "    processed_a = base_network(input_a)\n",
        "    processed_b = base_network(input_b)\n",
        "\n",
        "    # Calculate L1 distance between the processed inputs\n",
        "    distance = tf.reduce_sum(tf.abs(processed_a - processed_b), axis=1, keepdims=True)\n",
        "\n",
        "    # Create the Siamese model\n",
        "    siamese_model = models.Model([input_a, input_b], distance)\n",
        "\n",
        "    return siamese_model\n",
        "\n",
        "# Create pairs with data augmentation for training\n",
        "def create_pairs_with_augmentation(x, y, num_classes, num_pairs_per_class):\n",
        "    pairs, labels = [], []\n",
        "    class_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
        "\n",
        "    for class_idx in range(num_classes):\n",
        "        indices = class_indices[class_idx]\n",
        "        for _ in range(num_pairs_per_class):\n",
        "            idx1, idx2 = np.random.choice(indices, size=2, replace=False)\n",
        "            pairs.append([x[idx1], x[idx2]])\n",
        "            labels.append(1)\n",
        "\n",
        "            other_class_idx = np.random.choice(list(range(num_classes)), size=1)[0]\n",
        "            while other_class_idx == class_idx:\n",
        "                other_class_idx = np.random.choice(list(range(num_classes)), size=1)[0]\n",
        "\n",
        "            idx3 = np.random.choice(class_indices[other_class_idx])\n",
        "            pairs.append([x[idx1], x[idx3]])\n",
        "            labels.append(0)\n",
        "\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "# Instantiate the Siamese network\n",
        "input_shape = x_train.shape[1:]\n",
        "siamese_model = create_siamese_network(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create pairs for training and validation with data augmentation\n",
        "num_classes = len(np.unique(y_train))\n",
        "train_pairs, train_labels = create_pairs_with_augmentation(x_train, y_train, num_classes, num_pairs_per_class=100)\n",
        "test_pairs, test_labels = create_pairs_with_augmentation(x_test, y_test, num_classes, num_pairs_per_class=50)\n",
        "\n",
        "# Custom training loop\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "steps_per_epoch = len(train_pairs) // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    epoch_loss = []\n",
        "    epoch_accuracy = []\n",
        "\n",
        "    # Shuffle training pairs each epoch\n",
        "    indices = np.random.permutation(len(train_pairs))\n",
        "    train_pairs_shuffled = train_pairs[indices]\n",
        "    train_labels_shuffled = train_labels[indices]\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        batch_pairs = train_pairs_shuffled[step * batch_size : (step + 1) * batch_size]\n",
        "        batch_labels = train_labels_shuffled[step * batch_size : (step + 1) * batch_size]\n",
        "\n",
        "        loss, accuracy = siamese_model.train_on_batch([batch_pairs[:, 0], batch_pairs[:, 1]], batch_labels)\n",
        "        epoch_loss.append(loss)\n",
        "        epoch_accuracy.append(accuracy)\n",
        "\n",
        "    # Calculate average loss and accuracy for the epoch\n",
        "    mean_loss = np.mean(epoch_loss)\n",
        "    mean_accuracy = np.mean(epoch_accuracy)\n",
        "    print(f\"Mean Loss: {mean_loss:.4f}, Mean Accuracy: {mean_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate the Siamese network on test pairs\n",
        "test_loss, test_accuracy = siamese_model.evaluate([test_pairs[:, 0], test_pairs[:, 1]], test_labels)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tT6jekdHAeV",
        "outputId": "84128c6c-3a3b-4a1e-9261-82295bda1259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "Mean Loss: 7.6564, Mean Accuracy: 0.4979\n",
            "Epoch 2/20\n",
            "Mean Loss: 7.6326, Mean Accuracy: 0.4995\n",
            "Epoch 3/20\n",
            "Mean Loss: 7.6087, Mean Accuracy: 0.5010\n",
            "Epoch 4/20\n",
            "Mean Loss: 7.5770, Mean Accuracy: 0.5031\n",
            "Epoch 5/20\n",
            "Mean Loss: 7.6405, Mean Accuracy: 0.4990\n",
            "Epoch 6/20\n",
            "Mean Loss: 7.5849, Mean Accuracy: 0.5026\n",
            "Epoch 7/20\n",
            "Mean Loss: 7.6643, Mean Accuracy: 0.4974\n",
            "Epoch 8/20\n",
            "Mean Loss: 7.6326, Mean Accuracy: 0.4995\n",
            "Epoch 9/20\n",
            "Mean Loss: 7.6167, Mean Accuracy: 0.5005\n",
            "Epoch 10/20\n",
            "Mean Loss: 7.5452, Mean Accuracy: 0.5052\n",
            "Epoch 11/20\n",
            "Mean Loss: 7.6405, Mean Accuracy: 0.4990\n",
            "Epoch 12/20\n",
            "Mean Loss: 7.6167, Mean Accuracy: 0.5005\n",
            "Epoch 13/20\n",
            "Mean Loss: 7.6008, Mean Accuracy: 0.5016\n",
            "Epoch 14/20\n",
            "Mean Loss: 7.6246, Mean Accuracy: 0.5000\n",
            "Epoch 15/20\n",
            "Mean Loss: 7.6167, Mean Accuracy: 0.5005\n",
            "Epoch 16/20\n",
            "Mean Loss: 7.6008, Mean Accuracy: 0.5016\n",
            "Epoch 17/20\n",
            "Mean Loss: 7.6643, Mean Accuracy: 0.4974\n",
            "Epoch 18/20\n",
            "Mean Loss: 7.6643, Mean Accuracy: 0.4974\n",
            "Epoch 19/20\n",
            "Mean Loss: 7.5690, Mean Accuracy: 0.5036\n",
            "Epoch 20/20\n",
            "Mean Loss: 7.6087, Mean Accuracy: 0.5010\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 7.6246 - accuracy: 0.5000\n",
            "Test Loss: 7.6246, Test Accuracy: 0.5000\n"
          ]
        }
      ]
    }
  ]
}